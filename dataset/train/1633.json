{
    "score": [
        0.5714285714285714
    ],
    "extracted": [
        0
    ],
    "abstract": [
        "canada is using ai to study ` suicide-related behaviour ' on social media ."
    ],
    "id": "604790.train",
    "article": [
        "this month the canadian government is launching a pilot program to research and predict suicide rates in the country using artificial intelligence . the pilot will mine canadians ' social media posts `` in order to identify patterns associated with users who discuss suicide-related behaviour , '' according to a recently published contract document . the public health agency of canada plans to work with an ai company called advanced symbolics to trawl through more than 160,000 canadian social media accounts , according to cbc , but the contracted company says it will only use anonymized , public data . ",
        "the advanced symbolics website states that it does not use `` private communications '' and instead relies on `` publicly available information shared on social platforms by consenting individuals . '' advanced symbolics also told cbc that it does n't investigate isolated instances . specific details on how the firm 's technology will work in this pilot are thin . according to the contract , advanced symbolics will use its research to inform the public health agency of canada of suicide-related discussions by age and gender , as well as `` changes in patterns and available risk and protective factors . '' ",
        "the contract suggests that advanced symbolics can somehow detect `` ideation , behaviours , and communications . '' `` it 'd be a bit freaky if we built something that monitors what everyone is saying and then the government contacts you and said , ` hi , our computer ai has said we think you 're likely to kill yourself ' , '' kenton white , chief scientist with advanced symbolics , told cbc . we have reached out to advanced symbolics to learn more about how the technology works and how it will use the data collected throughout this pilot . ",
        "the pilot project is slated to start this month and wrap up by june 2018 . the canadian government expects to spend nearly $ 32,000 on the pilot , and could extend the contract by up to five years , completing the research in june 2023 for about $ 510,000 in total . approximately 11 people commit suicide daily in canada , according to the canadian association for suicide prevention . the canadian government is certainly not the first to use artificial intelligence as a means to identify and prevent suicide . facebook said in november of last year that it would expand its own ai-based suicide prevention program , `` using pattern recognition to detect posts or live videos where someone might be expressing thoughts of suicide , and to help respond to reports faster . ",
        "`` the key difference between facebook 's program and advanced symbolics ' pilot project is that the latter is n't trying to pinpoint individual cases on a platform , but rather identifying suicide trends in regions . the firm can reportedly alert the government to an increase in suicides up to three months ahead of time . it 's important to note that algorithms are not free from bias , and they also have a history of screwing up . but if the government is able to get ahead of an expected suicide spike , then it could , for instance , increase the presence of mental health professionals in a certain region or among a specific demographic . ",
        "outside of canada , other government entities have entertained the idea of deploying algorithms to deal with social issues . the white house declared a call for data scientists and technologists in september 2015 to aid in suicide prevention , and also hosted mental health hackathons across the country in december of that year . and this year , london 's metropolitan police announced that it was working with `` silicon valley providers '' to use machine learning to flag child abuse images on electronic devices . but , as we 've seen time and again , artificial intelligence is far from flawless , and the police force noted that the system still confused photos of naked bodies with photos of deserts . ",
        "if you struggle with suicidal thoughts please call the national suicide prevention hotline : 1-800-273-8255 . watch more : tech news .   "
    ]
}