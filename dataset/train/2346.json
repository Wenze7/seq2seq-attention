{
    "score": [
        1.0
    ],
    "extracted": [
        0
    ],
    "abstract": [
        "should social media companies screen content before it 's posted ?"
    ],
    "id": "14435.train",
    "article": [
        "should social media companies screen content before it 's posted and weed out offensive or extremist content ? setting aside the first amendment for a minute , here 's the question : would you be willing to accept a delay in posting content if it meant increased vetting from tech companies ? tech companies team upfacebook , youtube , twitter , and microsoft recently announced they were forming a global work group to team up to remove terrorist content . that comes on the heels of new legislation in the european union , such as germany proposing $ 6 million dollar fines for failing to remove hate speech postings in a timely manner . ",
        "the tech companies say they will talk best practices , content detection techniques , and transparency reporting for removals . tech companies , especially social media , have been under attack for not doing enough . it 's a slippery slope -- who gets banned ? in the past two years , twitters says it has suspended nearly a million accounts tied to offensive speech and thousands more with ties to russian propaganda . `` debate is part of a healthy society . but when someone tries to silence others or attacks them based on who they are or what they believe , that hurts us all and is unacceptable , '' posted facebook ceo mark zuckerberg . ",
        "what does facebook consider hate speech ? you might be surprised . whether you think it 's a violation of free speech or not , they are private companies . they can set their own terms for use and they have the right to discipline or remove users that violate those terms . the u. s. government is not allowed to restrict free speech . private companies , however , can choose to do so . tech companies `` not doing enough '' while i do n't have u. s. results , demos and opinium surveyed 2,000 british adults . ",
        "here 's a bit of what they found : 76 % do not believe tech companies are devoting enough resources to removing extremist content from their platforms . british citizens want action , and when extremist content is posted , they want it removed fast . the uk government has asked for a two-hour takedown window . right now , they gauge it can take an average of 36 hours , even though the four major social media platforms signed a voluntary code of conduct pledge in 2016 to takedown offensive content within 24 hours . with a reported two billion worldwide users , it 's simply impossible for facebook to manually monitor everything that 's posted . ",
        "part of the solution has to be automated , which means it 's an imperfect system . in the demos/opinium survey said they did n't think it was the job of tech companies to police content . maybe they worry about what would get policed . we might all agree the isis terrorist groups need to be censured , but who gets to decides what groups are extreme and worthy of being blocked . there really is no perfect system . how long would you wait ? the majority of those surveyed said delaying posts by 30 seconds or more would be acceptable if it meant more vetting of content . ",
        "30 % said a delay of three minutes or more would be acceptable .   "
    ]
}