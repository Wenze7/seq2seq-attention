{
    "score": [
        0.5
    ],
    "extracted": [
        0
    ],
    "abstract": [
        "building the ultimate corpus for watson knowledge studio training ."
    ],
    "id": "1071474.train",
    "article": [
        "watson knowledge studio is the most accessible cloud-based toolkit for annotating unstructured domain literature to create a custom machine-learning model . wks , built on top of sire , relies on machine pre-annotation and human annotation to create ground truth for the model to build its understanding . like any machine-learning model , the quality of the corpus of data used in the annotation process is critical to the success of a wks deployment . you want your training data to look like , feel like , and sound like the target data that you will be ultimately analyzing with your model . ",
        "but what if you do n't have enough data on hand to meet the suggest a minimum of 50 annotated examples per entity mention and up to 100 examples for relation ? perhaps you want to add more variety of data types to make your model a bit less homogeneous and more adaptable . you may find yourself searching high and low through external data or grabbing snippets of text from what data you do have available in order to get enough examples for a strong model . while searching for more trainable data , always aim to make your training data corpus representative of your target data . ",
        "characteristics of representative training data have similar : tone of languagevocabularyverbosityhow do you make sure you those snippets you use for training data stay true to what your targeted data looks like ? tone of language similaritywe can use watson tone analyzer to extract emotions and tones in our target data set to get a rich linguistic analysis broken into emotion , language , and social categories . tone analyzer outputs a numeric value of how prevalent tones of each category are in the text it looked at categorized into these sub-tones : emotion = anger , fear , joy , and sadnesslanguage = analytical , confident , and tentativesocial = openness , conscientiousness , extraversion , agreeableness , and emotional rangewhile all three categories are interesting in their own rights , for our purposes here , the language category will be most useful . ",
        "this will show you a piece of text 's style of writing which , as we covered earlier , is a critical factor in making sure your training data is representative . typically reports , common news articles , or abstracts are more analytical in nature while press releases , marketing material , or opinionated blogs are more confident in nature . if you take a bit of your target data text and run it through the service , you can compare it to a potential piece of training data , focusing on the language tones . every text will have different numeric results , so an exact match here is not important . ",
        "but rather , aim for a rough similarity in the language attributes of no more than a 10 -- 30 % difference between target data and training data . for a list of supported languages in watson tone analyzer , check out the api reference page . to jump start , you can clone this utility which allows you to run a . txt snippet through tone analyzer and prints the output . just follow the readme . or use your own little utility as your wish . vocabulary similaritydoes your target data use industry-specific terms , acronyms , or jargon ? ",
        "if so , it 's key to include training data that has the same level of industry expertise . if you do n't show the machine learning model an acronym , it has no way of knowing what that means ! if your target data is at a collegiate reading level but your training data is easy to read news data , you may want to reconsider acquiring different data to train on . verbosity similaritythe verbosity , or wordiness , of the language of your target data is equally important . scientific journals or academic papers frequently are usually simple and direct , describing a concept with little room for interpretation as they usually intend to convey a specific structured idea . ",
        "on the other hand , authors of news reports , blogs , user reviews , or works of fiction may use more colorful language to describe their ideas which may convey key points in a more circuitous way . but wait ! some news reports are succinct and factual ! some academic papers contain opinionated theses ! therein lies the key point - just because your target data is primarily one type of data , say a scientific journal , do n't assume that all are written similarly . be sure to read and select only those which are most similar to your target data . ",
        "machine-learning models are only as good as the data used to train themrepresentative training data is critical to success for wksother corpus building tips to keep in mindwhen creating your training corpus , try to store them in smaller snippets of text as this will generally yield better human annotation results especially for first model pass . examine a small set of sample docs after importing but prior to human annotation task assignment , ensuring page breaks and sentences were parsed correctly . keep training corpus size small during early stages of model development . as human annotators gain more experience , add more documents . ",
        "make sure your entire entity type system is found in your training data ! if you find that there 's a specific mention or relation that is not found in the training data , consider either finding more data or revising your entity type system . over representing some entities over other because they are more prevalent in your training can overweight the training towards those entities . even if it is not representative in terms of your target data population , aim to keep a relatively even level of entity mentions and relations in your sample data . this would mean adding more training segments for those entities or relations that are less common . ",
        "while the rule of thumb is 50 examples for entity mentions and 100 for relations , as models grow and the entity type system gets more complex , you may find yourself needing to go back and add more examples to reaffirm the system and boost those recall and precision numbers back up . similarly , if you have a particularly complex or nuanced relation , you may also need more examples . be patient ! you may have to delete documents or even change your thinking around which documents you train the model on once you see your results . ",
        "looking a detailed view of the confusion matrix in wks will help you diagnose what to do to improve your model . good luck and enjoy working with watson knowledge studio !   "
    ]
}